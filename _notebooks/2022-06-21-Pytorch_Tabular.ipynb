{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2479f0f0-9d57-4b44-b1c7-a331321f5c71",
   "metadata": {},
   "source": [
    "# Deep Networks with Pytorch-Tabular\n",
    "\n",
    "- branch: master\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: false\n",
    "- sticky_rank: 5\n",
    "- author: Huon Fraser\n",
    "- categories: [mangoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0eccea-66c4-4308-bfbc-d6421655fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import sys\n",
    "sys.path.append('/notebooks/Mangoes/src/')\n",
    "model_path  = '../models/'\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from codetiming import Timer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scikit_models import *\n",
    "from skopt.space import Real, Integer\n",
    "from lwr import LocalWeightedRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2331bfaf-b2e6-4c65-91a5-e408219267e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "mangoes=load_mangoes()\n",
    "\n",
    "train_data,test_data = train_test_split(mangoes)\n",
    "train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990)\n",
    "test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990)\n",
    "nrow,ncol=train_X.shape\n",
    "groups = train_cat['Pop']\n",
    "splitter=GroupKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7986344-5126-4065-b14f-083be6f6228c",
   "metadata": {},
   "source": [
    "PyTorch, the neural-network platform of choice for this project requires users to define their training and validation loops. While this provides excellent flexibility, higher-level API's like [pytorch-lighting](https://www.pytorchlightning.ai/) and [fastai](https://www.fast.ai/) cut out much of the boilerplate and integrate functionality like callbacks and logging. The [pytorch-tabular](https://pytorch-tabular.readthedocs.io/en/latest/) library builds upon the PyTorch-lightning library to provide an API for dealing with tabular data.\n",
    "\n",
    "In this notebook, we work through building an MLP model. In the next notebook, we will cover training and testing in a manner that is consistent with our earlier sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26b8a33-f6f1-4eb8-9273-007358ea5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from omegaconf import DictConfig\n",
    "from typing import Dict\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig,OptimizerConfig, TrainerConfig, ExperimentConfig,ModelConfig\n",
    "from pytorch_tabular.models import BaseModel\n",
    "from collections import OrderedDict\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6f2b9-70d3-47d6-b60f-cc29462390a9",
   "metadata": {},
   "source": [
    "## Defining a Model\n",
    "\n",
    "Within PyTorch-tabular custom networks can be defined by extending the BaseModel class, which in turn extends the PyTorch-Lightning LightningModule. All hyperparameters are passed in at initialisation by the config parameter and is accessible after super() has been called from self.hparams.\n",
    "\n",
    "Our first step is to write our MLP. We define our network in the \\_build_network function, consisting of two matrices (linear layers) separated by a ReLU activation layer. The number of inputs and outputs are controlled by hyperparameters inferred from the data while the width of the hidden layer is a user-controlled parameter.\n",
    "\n",
    "We also are required to define the forward class, which controls how data is passed through our network. The input of this function x, consists of a dictionary with continuous and categorical features broken down into x[\"continuous\"] and x[\"categorical\"]. Outputs of forward must be returned in a dictionary with predictions labelled by \"logits\". This is messy (and is unclear in their documentation). Hopefully, this is something that will be improved in future iterations of this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4835cd6-a9a0-4972-b9d5-326fc7c52e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MLPConfig(ModelConfig):\n",
    "    width: int = 10\n",
    "    \n",
    "class MLP(BaseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: DictConfig,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(config, **kwargs)\n",
    "\n",
    "    def _build_network(self):\n",
    "        layers = OrderedDict({'layer_1':nn.Linear(self.hparams[\"continuous_dim\"], self.hparams[\"width\"]),\n",
    "                             # 'act_1':nn.ReLU(),\n",
    "                              'layer_2':nn.Linear(self.hparams[\"width\"],self.hparams[\"output_dim\"])\n",
    "        })\n",
    "        self.model = nn.Sequential(layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x[\"continuous\"]\n",
    "        y_hat=  self.model.forward(x)\n",
    "        return  {'logits':y_hat}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a640d8-595e-415c-be0b-f97f34afae11",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configurations\n",
    "\n",
    "Data is expected to be a single pd.DataFrame including both X and y. This is a departure from the sklearn approach, and in the future, we'll work on a fix for this.\n",
    "For the time being, we merge our X and y and define as lists the names of our categorical columns, numerical columns, dates, and targets. We pass this metadata into a DataConfig object, which handles loading and transforming data for us. \n",
    "\n",
    "Similarly, we also initialise a TrainerConfig class and an OptimizerConfig class, which between them defines all the hyperparameters controlling training. We also define a ModelConfig, which specifies the parameters that determine how our model is built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6134f8a5-a2f8-4505-91a1-7762db97f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "num_col_names = train_X.columns.tolist()\n",
    "cat_col_names = []\n",
    "\n",
    "train_Xy = deepcopy(train_X)\n",
    "test_Xy = deepcopy(test_X)\n",
    "train_Xy['target']=train_y\n",
    "test_Xy['target']=test_y\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=32,\n",
    "    max_epochs=100,\n",
    "    gpus=-1, #index of the GPU to use. -1 means all available GPUs, None, means CPU\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "model_config = MLPConfig(task=\"regression\",\n",
    "                            learning_rate = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3d7ad-829d-4b6e-b67b-58961e8aa6ee",
   "metadata": {},
   "source": [
    "All the pieces are assembled in the TabularModel class. We pass in each config class and model_callable, a reference to our MLP class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e74552-6250-4ece-9e51-4899129d3104",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    model_callable = MLP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e2f37-35ec-4ae0-9f0c-4da227245e9a",
   "metadata": {},
   "source": [
    "To train a Tabular Model we call fit, passing in our training data (as a pd.DataFrame) and optionally validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1d764d-eb24-4124-a628-2282c0c9d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.1 K \n",
      "1 | loss  | MSELoss    | 0     \n",
      "-------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8d20d5ecaf4e2faffe84adf12a4623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 99 steps due to diverging loss.\n",
      "Restored states from the checkpoint file at /notebooks/Mangoes/_notebooks/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.15848931924611143\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 1.1 K \n",
      "1 | loss  | MSELoss    | 0     \n",
      "-------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1bfdac61aa4e56a438a921871e8656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 98it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabular_model.fit(train=train_Xy, validation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91f98a-4ab3-49d3-a864-0a8f9f655ff9",
   "metadata": {},
   "source": [
    "Then to evaluate a model we call evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1ca539-964c-4710-8930-30188407035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f45cf798aba4065bded07f6a0d92acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_mean_squared_error': 1.9310595989227295,\n",
      " 'test_mean_squared_error_0': 1.9310595989227295}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mean_squared_error': 1.9310595989227295,\n",
       "  'test_mean_squared_error_0': 1.9310595989227295}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.evaluate(test_Xy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c093b-ee5d-4d8f-b013-406707820311",
   "metadata": {},
   "source": [
    "Notice that there is a disconnect between the PyTorch-Tabular and scikit-learn API's. In the next part, we will work on an implementation that works the same for both scikit-learn and PyTorch-Tabular models. We will also introduce cross-validation for our neural networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
