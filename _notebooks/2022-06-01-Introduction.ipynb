{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c55fed1e-4e0b-4228-8410-5c075c0e3f50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "> Part 1 of the mangoes_blog project\n",
    "\n",
    "- branch: master\n",
    "- toc: true \n",
    "- badges: false\n",
    "- comments: false\n",
    "- sticky_rank: 1\n",
    "- author: Huon Fraser\n",
    "- categories: [mangoes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a86b5-ccb6-48f5-9c94-7f461daf7a0f",
   "metadata": {},
   "source": [
    "Deep learning for tabular data is experiencing a slight renaissance. Several methods have emerged that can compete to boosting methods (such as [XGBoost](https://xgboost.readthedocs.io/en/stable/)) in favourable conditions. NIR-spectrometry is a branch of tabular data that typically has two properties, large dimensionality and [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity), which in theory make it suited to deep networks. Multilayer Perceptron networks have been used for decades, and recently CNN architectures have been proposed, however, linear regression models and domain related preprocessing are still the predominant technique. For a detailed review of the NIR-spectra I defer to [Anderson and Walsh](https://opg.optica.org/jnirs/abstract.cfm?uri=jnirs-30-1-3).\n",
    "\n",
    "\n",
    "Applications in Industry use huge amounts of test instances, the horticuture industry for iinstance automated grading in horticure packhouses. These analysis rely on prior lab analysis for labelling data. As this analysis is relatively expensive (especially for large amounts of data), most datasets are proprietry. Enter the [Mangoes dataset](https://data.mendeley.com/datasets/46htwnp833/1) (Anderson et al.), a large NIR-spectroscopy dataset for estimating the relationship between spectra and the dry matter, a measure of maturity of mango fruit.\n",
    "\n",
    "\n",
    "This is first part of a series comparing a range of deep networks to classical approaches the Mangoes data set. The advantage of the Mangoes dataset is that models (and performance metrics) are publicly available for both classical ([Anderson et al.](https://www.researchgate.net/publication/342056149_Achieving_robustness_across_season_location_and_cultivar_for_a_NIRS_model_for_intact_mango_fruit_dry_matter_content)) and deep network ([Mishra and Passos](https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/full/10.1002/cem.3367)) approaches. We can start by (re-)producing similar work and once results are inline we can veer off. The plan is to start with simple linear models and gradually adding complexity. Likel we will do the same for deep networks. Currently the following  parts are sketched in, with the plan for deep networks being less clear:\n",
    "\n",
    "1) Introduction - Exploratory data analysis and a first linear model.\n",
    "2) Evaluation - Setup our cross validation and search methods.\n",
    "3) Spectral Regressions - Cover regression techniques commonly used for spectral applications.\n",
    "4) Spectral Preprocessing - Cover preprocessing techniques commonly used for spectral applications.\n",
    "5) Black Box tabular - Compare results to ensembles like RandomForest and XGGoost.\n",
    "6) Deep Networks ... \n",
    "\n",
    "\n",
    "This notebook introduces the Mangoes data set and performs expoloratory data analysis. These are done in a literate programming style with text, code and outputs alongside each other. We use the [nbdev](https://www.fast.ai/2019/12/02/nbdev/) library, code blocks marked with #export are reused in future notebooks, allowing us to incrementally build a library of tools.  Occasionally code segments are deemed too complex/large for a notebook and these will be available in the github repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201ca79-1ad8-4a92-91ae-ff4fd6695fa3",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "We begin with imports and library settings which we will use for all notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408b9f20-2e04-48fb-946f-ad74dc1ace83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m__init__.pxd:942\u001b[0m, in \u001b[0;36mnumpy.import_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0x10 but this version of numpy is 0xf",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# hack but overkill to use re\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32mpandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.hashtable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/missing.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.missing\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/tslibs/__init__.py:30\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutOfBoundsTimedelta, localize_pydatetime\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Resolution\n",
      "File \u001b[0;32mpandas/_libs/tslibs/conversion.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.conversion\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/tslibs/nattype.pyx:27\u001b[0m, in \u001b[0;36minit pandas._libs.tslibs.nattype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m__init__.pxd:944\u001b[0m, in \u001b[0;36mnumpy.import_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#collapse-hide\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/__init__.py:34\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# hack but overkill to use re\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot import name \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext --inplace --force\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     41\u001b[0m     get_option,\n\u001b[1;32m     42\u001b[0m     set_option,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     options,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "#collapse-hide\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871eb2d-b7d9-40f7-bad7-ebe48627fba8",
   "metadata": {},
   "source": [
    "Next we define methods to parse the Mangoes data set. We write a method to load the data (load_mangoes). Training and test splits are provided in the data (for reproducability) and we write a method to seperate these (train_test_split). We then write a method to seperate the spectra data, the target, and other variables into seperate dataframes, with the option to limit the spectra to certain wavelengths. More details about these partitions will be provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e9e22-a7f5-41aa-80dc-8ae8c294c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mangoes():\n",
    "    mangoes = pd.read_csv(\"../data/mangoes_raw.csv\")\n",
    "\n",
    "    unique_spectra = mangoes['DM'].unique()\n",
    "    fruit_id_dict = {u:i for i,u in enumerate(unique_spectra)}\n",
    "    mangoes['Fruit_ID'] = mangoes['DM'].apply(lambda x: fruit_id_dict[x])\n",
    "    return mangoes\n",
    "\n",
    "def train_test_split(data):\n",
    "    train_inds = np.logical_not(data['Set']=='Val Ext')\n",
    "    test_inds = data['Set']=='Val Ext'\n",
    "\n",
    "    train_data = data[train_inds]\n",
    "    test_data = data[test_inds]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def X_y_cat(data,min_X=285,max_X=1200):\n",
    "    cat_vars=['Set','Season','Region','Date','Type','Cultivar','Pop','Temp','Fruit_ID']\n",
    "    y_vars = ['DM']\n",
    "    X_vars = [i for i in data.columns if (not i in y_vars) and (not i in cat_vars)]\n",
    "    X_vars = [i for i in X_vars if (int(i)>= min_X) and (int(i)<= max_X)]\n",
    "    return data[X_vars], data[y_vars], data[cat_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa00253-f1b0-47bc-9541-6f9d4bd51c2e",
   "metadata": {},
   "source": [
    "Running these methods we see that the dataset has 11691 instances, 10243 of which are marked for training and 1448 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145b98f-749f-4c10-995e-8a77a0d0fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mangoes = load_mangoes()    \n",
    "train_data,test_data = train_test_split(mangoes)\n",
    "\n",
    "train_X, train_y, train_cat= X_y_cat(train_data)\n",
    "test_X, test_y, test_cat = X_y_cat(test_data)\n",
    "nrow,ncol=train_X.shape\n",
    "\n",
    "print(f'Data shape: {mangoes.shape}')\n",
    "print(f'Train data shape: {train_data.shape}')\n",
    "print(f'Test data shape: {test_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a016b2-3eac-4bc8-bc22-e0bbc6dd5613",
   "metadata": {},
   "source": [
    "Taking a step back, below we show a sample of the entire dataset. The first 8 columns are metadata and the 9th, DM, is the target variable. The remaining columns are the spectras, correspnding to readings over 3nm intervals from 285-1200nm.   Multiple readings are made for each mango fruit. Each spectra is included twice, corresponding to two spectra readings. Several fruit are read more than twice, for example multiple readings are made at different temperatures. Above we assigned a 'Fruit_ID' column based on unique values of DM. This isn't pefect, different fruit may have the same DM at the precision present in the dataset, or fruit may have different DM values but may be a useful proxy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6bf63-c88f-4565-9a1e-cd8ccaf510f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mangoes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341a528-812b-4e47-8ee0-4df102d67845",
   "metadata": {},
   "source": [
    "We also show a selection of spectra from the training portion of the dataset. Missing values in the dataset are coded as 0. Values are missing at each end of the spectrum and are coded as 0. Several columns are completely 0, indicated by the flat lines at each of the below figure. Other columns are partially 0, likely due to different instruments being used to measure different groups of samples. The range of data which includes no missing data is 513-1050nm. Indidently, this is the range that cuts of much of the noise seen at each end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c65dc-d68e-484c-a03d-3b297a5487c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax=train_X.mean().plot(label='Mean',legend=True)\n",
    "for i in range(0,4):\n",
    "    train_X.iloc[i,:].plot(label=i,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727c0c7-fc26-41b4-9634-31808518612d",
   "metadata": {},
   "source": [
    "We also show the distributuon of the target (DM) for the non-test partitions of the data. This is fairly symmetrical and no outliers are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66298bc0-28c9-4e3f-9665-a5ca928683d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.plot.hist(bins=50,density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28141dad-f4e2-48e2-8ed4-426b228be5e8",
   "metadata": {},
   "source": [
    "Anderson et al. used the 684-990nm range for their analysis, so for the sake of comparison we will also use this range of wavelengths. This range gives significantly smoother data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f722a-e316-4e47-8aa4-5ed9969636fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990)\n",
    "test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990)\n",
    "print(f'Number of selected spectra variables: {train_X.shape[1]}')\n",
    "\n",
    "ax=train_X.mean().plot(label='Mean',legend=True)\n",
    "for i in range(0,4):\n",
    "    train_X.iloc[i,:].plot(label=i,legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e014a8a-c26c-4672-9fad-d158ecb453b4",
   "metadata": {},
   "source": [
    "## Expoloratory Data Analysis\n",
    "\n",
    "We now dive into all the non-spectra data present in the dataset. We do this for the training data as we want to avoid learning about the test data set for now. We look at distributions of the target and the mean spectra for each categorical variable.\n",
    "\n",
    "The **Set** variable deliminates data into training (cal), tuning (tuning) and test (val ext) sets. Previously we used this variable by combining the cal and tuning sets into a combined training data set. Each set has near identical mean spectra; indicating that these splits can be replaced by any random sampling method. DM distributions vary slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bfe3b-d79f-40aa-8ea9-813b5685b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Set'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Set')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Set'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bb8521-2c39-411e-a89a-afea35899d0e",
   "metadata": {},
   "source": [
    "Data is taken over 4 growing **Seasons**. The 4th season is used for the test set, with seasons 1-3 grouped and then divided into training and tuning sets. As for set, pectra readings from season are consistent, while DM varies slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aeea80-143d-4d7a-9a82-647e952987b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Season'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Season')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31be36e-e74a-4669-a639-792ee9a4e20d",
   "metadata": {},
   "source": [
    "The two growing **Regions**, NT and QD also display similar spectra readings with slihgtly different DM distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afaa6e8-b0c9-47f2-bba9-5e19c1b267a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Region'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Region')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39afd4d-4175-40a0-886b-583cdb686216",
   "metadata": {},
   "source": [
    "The Physiological stage, or **Type**, Hard Green or Ripened significantly influences spectra readings and ripened fruit having a much tighter DM distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e03502a-5370-49ee-b66a-ca042aa5b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Type'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Type')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707441b8-0cfb-4625-b484-d25e274f022f",
   "metadata": {},
   "source": [
    "Each **Cultivar** displays a slightly different mean spectrs; cultivars display more variance at the low end and converge towards the high end. DM distributins vary highly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6731fe-ab06-473e-be39-e3e3e71eff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Cultivar'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Cultivar')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Cultivar'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79b708-190a-4afe-b7d7-0da4ef7faf6f",
   "metadata": {},
   "source": [
    "Mangoes are taken from 94 different **Populations** (orchards). This variable imacts spectra readings to a greater degree than cultivar. Its likely that there is significant overlap between the cultivar and population variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97a139-0396-484a-a2da-e5093d2dc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data['DM'].hist(by=train_data['Pop'],bins=10,sharey=True,sharex=True)\n",
    "train_data.groupby('Pop')[train_X.columns].mean().transpose().plot(legend=False)\n",
    "train_data['Pop'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78142321-6e18-43d9-a5b4-67b59247d086",
   "metadata": {},
   "source": [
    "Readings at different **Temperature** show the same spectra reading. DM results are identical for each temeperature, which is expected as they share the same lab based label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8967da8-bcb7-4094-bea4-0752f90d5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['DM'].hist(by=train_data['Temp'],bins=30,sharey=True,sharex=True,density =True)\n",
    "train_data.groupby('Temp')[train_X.columns].mean().transpose().plot()\n",
    "train_data['Temp'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f38cd-99c3-439a-88fc-5c25c215dd07",
   "metadata": {},
   "source": [
    "## Explaining Variance\n",
    "\n",
    "Having examined each categorical variable in turn we now perform a simple variance analysis. We build a linear model related DM to categorical variables. This is done for each combination of categorical variable (with temperature and date excluded), so that by using $R^2$ scores we can calculate the marginal contribution (to percent of variance explained) by each categorical variable.\n",
    "\n",
    "Iterating through each combination of variables, we see that Pop explains 0.5474% of the variance. Including Cultivar adds an extra 0.002% for a toal of 0.5476%. We conclude that the effect of Region, Type, and Season variables are solely due to aggregates of Pop, or conversely, that the Pop variable aborbs all of the information of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98260063-176b-4b85-82a1-4bcfd51e9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import combinations\n",
    "\n",
    "for i in range(1,6):\n",
    "    oh_vars=['Season','Region','Type','Cultivar','Pop']\n",
    "    for selected in list(combinations(oh_vars,i)):\n",
    "        selected = list(selected)\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(train_data[selected])\n",
    "        oh_vars1 = enc.transform(train_data[selected])\n",
    "\n",
    "        lin = LinearRegression()\n",
    "        lin.fit(oh_vars1,train_y)\n",
    "        score = lin.score(oh_vars1,train_y)\n",
    "\n",
    "        print(f'R2 score is {score:.4f} for {selected}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff2462-a0ce-49d8-a74d-9c3f662e6ae0",
   "metadata": {},
   "source": [
    "To further analyse this we group the data by pop. With the exception of Pop 52, which contains both KP, and LadyG cultivar, each population includes just a single unique value for each categorical value.\n",
    "Variables like Region or Cultivar which may well effect dry matter, we just cannot measure this as their variance is absorbed by Pop. If we wanted to compare say Cultivar and Pop we would need a dataset containing multiple cultivars for each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03840f78-e916-4fa4-b684-eddff5741057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mangoes.groupby('Pop').agg({cat_var : 'unique' for cat_var in train_cat})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f243ff1-4db1-4ac0-9cfb-d590bd6a6ea5",
   "metadata": {},
   "source": [
    "## A Linear Model and Summary\n",
    "\n",
    "This notebook has introduced the mangoes dataset and performed simple expoloratory analysis, finding that the Pop variable explains over half the variance in the dataset.  This has implications for test set performance, with the training and test sets consisting of distinct sets of populations. \n",
    "\n",
    "In the next few notebooks we will get into the meat and potatoes of building regression models. To finish this notebook off we train a linear model on th training portion of the data, which gives an MSE score of 1.1290 on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805143a-5be7-464c-a5e7-9e3b46cf1be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = LinearRegression()\n",
    "model.fit(train_X,train_y)\n",
    "preds = model.predict(test_X)\n",
    "mse = mean_squared_error(test_y,preds)\n",
    "print(f\"Test set MSE is: {mse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
