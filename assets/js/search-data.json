{
  
    
        "post0": {
            "title": "Deep Networks (Draft)",
            "content": "from copy import deepcopy from sklearn.metrics import r2_score, mean_squared_error import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; . Cross-Validation . So far we have implemented a minimum-viable model and evaluation. We now wrap this into a cross-validation framework. . First we need to consider a key design choice. For our sklearn models, cross-validation led to building multiple versions of a model with slightly different parameters. For neural networks, with optimising being a highly stochastic gradient descent path, there is no gurantee that cross-validation folds are similar, or that folds resemble the final model trained on all the data. After running cross-validation, we let the user define how to build the final model; None, for building no final model to save time, &quot;All&quot;, to train a model on the whole training set, or &quot;Ensemble&quot;, to build an ensemble on the cross-validation folds. . We define our ensemble implementation below. At the moment we just pass in each model. IN the future we may instead pass in a location of a savefile for each model, or a single model and a list of locations to get weights from. . @dataclass class EnsembleConfig(ModelConfig): models: list = [] voting : str = &quot;Mean&quot; class Ensemble(EnsembleModel): def __init__( self, config: DictConfig, **kwargs ): super().__init__(config, **kwargs) def _build_network(self): self.models = self.hparams[&quot;continuous_dim&quot;] def forward(self,x): x = x[&quot;continuous&quot;] y_hats=torch.zeros(x.shape[1],len(self.models)) for i,model in enumerate(models): y_hats[:,i]= self.model.forward(x)[&#39;logits&#39;] if voting == &quot;Mean&quot;: y_hat = torch.mean(y_hats) return {&#39;logits&#39;:y_hat} . from sklearn.model_selection import GroupKFold, KFold def cross_validate(model,X,y,splitter=GroupKFold(),groups=None,plot=False,save_loc=None,final_model=&quot;Ensemble&quot;): #Ensemble, &quot;All&quot;, None #combine X and y Xy = deepcopy(X) Xy[&quot;target&quot;]=y preds = None ys = None models = [] for fold, (inds1,inds2) in enumerate(splitter.split(X,y,groups)): model.fit(X.iloc[inds1,:],y.iloc[inds1,:]) pred = model.predict(X.iloc[inds2,:]) if preds is None: preds = pred ys = y.iloc[inds2,:] else: preds = np.concatenate((preds,pred),axis=0) ys = np.concatenate((ys,y.iloc[inds2,:]),axis=0) if final_model == &quot;Ensemble&quot;: models.append(deepcopy(model)) r2 = r2_score(ys,preds) mse = mean_squared_error(ys,preds) if plot: ys = ys.flatten() preds = preds.flatten() m, b = np.polyfit(ys, preds, 1) fig, ax = plt.subplots() ls = np.linspace(min(ys),max(ys)) ax.plot(ls,ls*m+b,color = &quot;black&quot;, label = r&quot;$ hat{y}$ = &quot;+f&quot;{m:.4f}y + {b:.4f}&quot;) ax.scatter(x=ys,y=preds,label = r&quot;$R^2$&quot; + f&quot;={r2:.4f}&quot;) ax.set_xlabel(&#39;True Values&#39;) ax.set_ylabel(&#39;Predicted Values&#39;) ax.legend(bbox_to_anchor=(0.5,1)) if not save_loc is None: fig.savefig(save_loc) if final_model == &quot;Ensemble&quot;: #create new tabular model, passing in same configs but with an ensemble ens_config = EnsembleConfig(models=models) ensemble = TabularModel( data_config=model.data_config, optimizer_config=model.optimizer_config, trainer_config=model.trainer_config, model_config=ens_config, model_callable = Ensemble ) model = ensemble elif final_model == &quot;All&quot;: #train final model on all data model = model.fit(train=Xy) else: #ignore training the final model, for computation saving purposes model = None return model, mse . def evaluate(model,train_X,train_y,test_X,test_y,plot=False,save_loc=None,log=True): test_y=test_y.values.flatten() model.fit(train_X,train_y) preds = model.predict(test_X) r2 = r2_score(test_y,preds) mse = mean_squared_error(test_y,preds) if log: print(f&quot;Test set MSE: {mse:.4f}&quot;) if plot: preds=preds.flatten() m, b = np.polyfit(test_y, preds, 1) fig, ax = plt.subplots() ls = np.linspace(min(test_y),max(test_y)) ax.plot(ls,ls*m+b,color = &quot;black&quot;, label = r&quot;$ hat{y}$ = &quot;+f&quot;{m:.4f}y + {b:.4f}&quot;) ax.scatter(x=test_y,y=preds,label = r&quot;$R^2$&quot; + f&quot;={r2:.4f}&quot;) ax.set_xlabel(&#39;True Values&#39;) ax.set_ylabel(&#39;Predicted Values&#39;) ax.legend(bbox_to_anchor=(0.5,1)) if not save_loc is None: fig.savefig(save_loc) return model, mse .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/07/25/Deep_Networks.html",
            "relUrl": "/mangoes/2022/07/25/Deep_Networks.html",
            "date": " • Jul 25, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Deep Networks with Pytorch-Tabular",
            "content": "import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; import pathlib import pandas as pd import numpy as np from matplotlib import pyplot as plt from tqdm.notebook import tqdm from codetiming import Timer from sklearn.model_selection import GroupKFold from scikit_models import * from skopt.space import Real, Integer from lwr import LocalWeightedRegression from sklearn.pipeline import Pipeline import warnings warnings.filterwarnings(&#39;ignore&#39;) . . mangoes=load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) nrow,ncol=train_X.shape groups = train_cat[&#39;Pop&#39;] splitter=GroupKFold() . . PyTorch, the neural-network platform of choice for this project requires users to define their training and validation loops. While this provides excellent flexibility, higher-level API&#39;s like pytorch-lighting and fastai cut out much of the boilerplate and integrate functionality like callbacks and logging. The pytorch-tabular library builds upon the PyTorch-lightning library to provide an API for dealing with tabular data. . In this notebook, we work through building an MLP model. In the next notebook, we will cover training and testing in a manner that is consistent with our earlier sklearn models. . import torch import torch.nn as nn import torch.nn.functional as F from omegaconf import DictConfig from typing import Dict from dataclasses import dataclass, field from pytorch_tabular import TabularModel from pytorch_tabular.config import DataConfig,OptimizerConfig, TrainerConfig, ExperimentConfig,ModelConfig from pytorch_tabular.models import BaseModel from collections import OrderedDict from pytorch_tabular.models import CategoryEmbeddingModelConfig . . Defining a Model . Within PyTorch-tabular custom networks can be defined by extending the BaseModel class, which in turn extends the PyTorch-Lightning LightningModule. All hyperparameters are passed in at initialisation by the config parameter and is accessible after super() has been called from self.hparams. . Our first step is to write our MLP. We define our network in the _build_network function, consisting of two matrices (linear layers) separated by a ReLU activation layer. The number of inputs and outputs are controlled by hyperparameters inferred from the data while the width of the hidden layer is a user-controlled parameter. . We also are required to define the forward class, which controls how data is passed through our network. The input of this function x, consists of a dictionary with continuous and categorical features broken down into x[&quot;continuous&quot;] and x[&quot;categorical&quot;]. Outputs of forward must be returned in a dictionary with predictions labelled by &quot;logits&quot;. This is messy (and is unclear in their documentation). Hopefully, this is something that will be improved in future iterations of this library. . @dataclass class MLPConfig(ModelConfig): width: int = 10 class MLP(BaseModel): def __init__( self, config: DictConfig, **kwargs ): super().__init__(config, **kwargs) def _build_network(self): layers = OrderedDict({&#39;layer_1&#39;:nn.Linear(self.hparams[&quot;continuous_dim&quot;], self.hparams[&quot;width&quot;]), # &#39;act_1&#39;:nn.ReLU(), &#39;layer_2&#39;:nn.Linear(self.hparams[&quot;width&quot;],self.hparams[&quot;output_dim&quot;]) }) self.model = nn.Sequential(layers) def forward(self,x): x = x[&quot;continuous&quot;] y_hat= self.model.forward(x) return {&#39;logits&#39;:y_hat} . Configurations . Data is expected to be a single pd.DataFrame including both X and y. This is a departure from the sklearn approach, and in the future, we&#39;ll work on a fix for this. For the time being, we merge our X and y and define as lists the names of our categorical columns, numerical columns, dates, and targets. We pass this metadata into a DataConfig object, which handles loading and transforming data for us. . Similarly, we also initialise a TrainerConfig class and an OptimizerConfig class, which between them defines all the hyperparameters controlling training. We also define a ModelConfig, which specifies the parameters that determine how our model is built. . from copy import deepcopy num_col_names = train_X.columns.tolist() cat_col_names = [] train_Xy = deepcopy(train_X) test_Xy = deepcopy(test_X) train_Xy[&#39;target&#39;]=train_y test_Xy[&#39;target&#39;]=test_y data_config = DataConfig( target=[&#39;target&#39;], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented continuous_cols=num_col_names, categorical_cols=cat_col_names, ) trainer_config = TrainerConfig( auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate batch_size=32, max_epochs=100, gpus=-1, #index of the GPU to use. -1 means all available GPUs, None, means CPU ) optimizer_config = OptimizerConfig() model_config = MLPConfig(task=&quot;regression&quot;, learning_rate = 1e-3) . All the pieces are assembled in the TabularModel class. We pass in each config class and model_callable, a reference to our MLP class. . tabular_model = TabularModel( data_config=data_config, model_config=model_config, optimizer_config=optimizer_config, trainer_config=trainer_config, model_callable = MLP ) . To train a Tabular Model we call fit, passing in our training data (as a pd.DataFrame) and optionally validation . tabular_model.fit(train=train_Xy, validation=None) . Global seed set to 42 GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | model | Sequential | 1.1 K 1 | loss | MSELoss | 0 - 1.1 K Trainable params 0 Non-trainable params 1.1 K Total params 0.004 Total estimated model params size (MB) Global seed set to 42 LR finder stopped early after 99 steps due to diverging loss. Restored states from the checkpoint file at /notebooks/Mangoes/_notebooks/lr_find_temp_model.ckpt Learning rate set to 0.15848931924611143 LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | model | Sequential | 1.1 K 1 | loss | MSELoss | 0 - 1.1 K Trainable params 0 Non-trainable params 1.1 K Total params 0.004 Total estimated model params size (MB) Global seed set to 42 . Then to evaluate a model we call evaluate. . tabular_model.evaluate(test_Xy) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_mean_squared_error&#39;: 1.9310595989227295, &#39;test_mean_squared_error_0&#39;: 1.9310595989227295} -- . [{&#39;test_mean_squared_error&#39;: 1.9310595989227295, &#39;test_mean_squared_error_0&#39;: 1.9310595989227295}] . Notice that there is a disconnect between the PyTorch-Tabular and scikit-learn API&#39;s. In the next part, we will work on an implementation that works the same for both scikit-learn and PyTorch-Tabular models. We will also introduce cross-validation for our neural networks. .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/21/Pytorch_Tabular.html",
            "relUrl": "/mangoes/2022/06/21/Pytorch_Tabular.html",
            "date": " • Jun 21, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Wrapping up Linear Models",
            "content": "import pathlib import pandas as pd import numpy as np import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; from matplotlib import pyplot as plt from codetiming import Timer from sklearn.model_selection import GroupKFold from scikit_models import * from skopt.space import Real, Integer from lwr import LocalWeightedRegression from sklearn.pipeline import Pipeline import warnings warnings.filterwarnings(&#39;ignore&#39;) . . RuntimeError Traceback (most recent call last) File __init__.pxd:942, in numpy.import_array() RuntimeError: module compiled against API version 0x10 but this version of numpy is 0xf During handling of the above exception, another exception occurred: ImportError Traceback (most recent call last) File /opt/conda/lib/python3.10/site-packages/pandas/__init__.py:30, in &lt;module&gt; 29 try: &gt; 30 from pandas._libs import hashtable as _hashtable, lib as _lib, tslib as _tslib 31 except ImportError as e: # pragma: no cover 32 # hack but overkill to use re File /opt/conda/lib/python3.10/site-packages/pandas/_libs/__init__.py:13, in &lt;module&gt; 1 __all__ = [ 2 &#34;NaT&#34;, 3 &#34;NaTType&#34;, (...) 9 &#34;Interval&#34;, 10 ] &gt; 13 from pandas._libs.interval import Interval 14 from pandas._libs.tslibs import ( 15 NaT, 16 NaTType, (...) 21 iNaT, 22 ) File pandas/_libs/interval.pyx:1, in init pandas._libs.interval() File pandas/_libs/hashtable.pyx:1, in init pandas._libs.hashtable() File pandas/_libs/missing.pyx:1, in init pandas._libs.missing() File /opt/conda/lib/python3.10/site-packages/pandas/_libs/tslibs/__init__.py:30, in &lt;module&gt; 29 from . import dtypes &gt; 30 from .conversion import OutOfBoundsTimedelta, localize_pydatetime 31 from .dtypes import Resolution File pandas/_libs/tslibs/conversion.pyx:1, in init pandas._libs.tslibs.conversion() File pandas/_libs/tslibs/nattype.pyx:27, in init pandas._libs.tslibs.nattype() File __init__.pxd:944, in numpy.import_array() ImportError: numpy.core.multiarray failed to import The above exception was the direct cause of the following exception: ImportError Traceback (most recent call last) Input In [1], in &lt;cell line: 3&gt;() 1 #collapse-hide 2 import pathlib -&gt; 3 import pandas as pd 4 import numpy as np 6 import sys File /opt/conda/lib/python3.10/site-packages/pandas/__init__.py:34, in &lt;module&gt; 31 except ImportError as e: # pragma: no cover 32 # hack but overkill to use re 33 module = str(e).replace(&#34;cannot import name &#34;, &#34;&#34;) &gt; 34 raise ImportError( 35 f&#34;C extension: {module} not built. If you want to import &#34; 36 &#34;pandas from the source directory, you may need to run &#34; 37 &#34;&#39;python setup.py build_ext --inplace --force&#39; to build the C extensions first.&#34; 38 ) from e 40 from pandas._config import ( 41 get_option, 42 set_option, (...) 46 options, 47 ) 49 # let init-time option registration happen ImportError: C extension: numpy.core.multiarray failed to import not built. If you want to import pandas from the source directory, you may need to run &#39;python setup.py build_ext --inplace --force&#39; to build the C extensions first. . mangoes=load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) nrow,ncol=train_X.shape groups = train_cat[&#39;Pop&#39;] splitter=GroupKFold() . . Ensemble methods . We now compare our approach to off-the-shelf ensemble models that are typically the state of the art for tabular problems. We train off-the-shelf variants of Random Forest, the default sklearn Gradient Boosting Regression and XGBoost. A caveat here is that each of these models could probably be optimised further. Initial performance with standardisation preprocessing was disappointing so we used PLS preprocessing for these experiments. . Random Forest . from sklearn.ensemble import RandomForestRegressor model = Pipeline([ (&#39;scaler&#39;, PLSRegression()), (&#39;model&#39;,RandomForestRegressor()) ]) space = [Integer(2,ncol,name=&#39;scaler__n_components&#39;), ] opt = Optimiser(space,model,train_X,train_y,splitter=splitter,groups=groups) model_forest,result_forest = opt.optimise(save_file=model_path+&#39;5_random_forest&#39;) . Scikit-learn Gradient Boosting . from sklearn.ensemble import GradientBoostingRegressor model = Pipeline([ (&#39;scaler&#39;, PLSRegression()), (&#39;model&#39;,GradientBoostingRegressor(random_state=0)) ]) space = [Integer(2,ncol,name=&#39;scaler__n_components&#39;), ] opt = Optimiser(space,model,train_X,train_y,splitter=splitter,groups=groups) model_boost,result_boost = opt.optimise(save_file=model_path+&#39;5_gradboost&#39;) . XGBoost . import xgboost as xgb model = Pipeline([ (&#39;scaler&#39;, PLSRegression()), (&#39;model&#39;,xgb.XGBRegressor(tree_method=&quot;gpu_hist&quot;)) ]) space = [ Integer(2,ncol,name=&#39;scaler__n_components&#39;) ] opt = Optimiser(space,model,train_X,train_y,splitter=splitter,groups=groups) model_xg, result_xg = opt.optimise(save_file=model_path+&#39;5_xgboost&#39;) . Ensembles of PLS-LWR . We&#39;ve left them until last because typically ensembles will always give a better performance; any of the models looked at in the previous 3 parts could be ensembled. We take our previous best model (SG-PLS-LWR) and build a bagging regressor ensemble. This builds 10 copies of a model, with each trained on a sample (with replacement) of the dataset. Predictions are then made by taking the mean of the ensemble. . Results are no better than for the non-ensembled version. A possible explanation is that bagging reduces the density of the feature space, interfering with the locally weighted regressions. . from sklearn.ensemble import BaggingRegressor from joblib import dump, load pipe = load(model_path+&#39;4_pp-pls-lwr_model2.joblib&#39;) model = BaggingRegressor(pipe) mse = cross_validate(model,train_X,train_y,splitter=splitter,groups=groups,plot=True) print(f&#39;Train set MSE: {mse}&#39;) . model, mse_test = evaluate(model,train_X,train_y,test_X,test_y,plot=True) . Comparing Techniques . So far in this series, we started with a multiple linear regression (LR) and added complexity; feature extraction with partial least squares (PLS), lazy instance weights with locally weighted regressions (LWR) and preprocessing with Savitsky Golay (SG). Adding each of these components incrementally improved performance during cross-validation, although the hyperparameter settings were not always consistent. The final model in this series (SG-PLS-LWR) gave a cross-validation MSE of 0.7223 and a test MSE of 0.7686. . When we compared this model to off-the-shelf ensembles (including XGBoost) and a bagging-ensemble extension, we found that these underperformed our model. To round out this part of the series we compare our results to the original Mangoes results achieved by Anderson et al. . In the table below we compare two models by Anderson et al, LPLS, their best performing locally weighted PLS model, and Ensemble, their best ensemble-based model to the models we have built in this series. Our approach gave substantially better results than both models. Without going into too much detail, this is likely due to the Anderson et al. models fixing the number of components for PLS to a relatively low number, whereas we kept this hyperparameter flexible. . Model CV Score Test Score . LR | 0.8157 | 1.1147 | . PLS-LR | 0.8116 | - | . LWR | 0.7868 | - | . PLS-LWR | 0.7520 | 0.8113 | . SG-PLS-LWR | 0.7223 | 0.7686 | . E(SG-PLS-LWR) | 0.7236 | 0.7801 | . Anderson et al. LPLS | 0.66 | 0.887 | . Anderson et al. Ensemble | 0.56 | 0.850 | .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/17/Benchmarks.html",
            "relUrl": "/mangoes/2022/06/17/Benchmarks.html",
            "date": " • Jun 17, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Domain Related Preprocessing",
            "content": "So far in this series, we have introduced the mangoes dataset and built up a regression model that uses PLS preprocessing and lazy local instance weights to achieve an MSE (test set) of 0.8117. Many NIR-spectroscopy applications make use of domain-related preprocessing, and we now look at enhancing our model with one of these schemes. . import pathlib import pandas as pd import numpy as np from matplotlib import pyplot as plt from tqdm.notebook import tqdm import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; from codetiming import Timer from sklearn.model_selection import GroupKFold from scikit_models import * from skopt.space import Real, Integer #np.random.seed(123) from sklearn.pipeline import Pipeline import warnings warnings.filterwarnings(&#39;ignore&#39;) . . mangoes=load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) nrow,ncol=train_X.shape groups = train_cat[&#39;Pop&#39;] splitter=GroupKFold() . . Before we delve into preprocessing methods we write a small tool so that we can visualise the effect of a spectral preprocessing regime. As a first example, below, we show that standardisation greatly introduces the variance of most spectra points. . from sklearn.preprocessing import StandardScaler def plot_sample(scaler=StandardScaler(), n_samples=5): i = [i for i in range(n_samples)] sample = train_X.iloc[i,:] trans = pd.DataFrame(scaler.fit_transform(train_X)).iloc[i,:] for j,_ in enumerate(i): sample.iloc[j,:].plot(label=f&#39;Raw {j}&#39;,color=&#39;Grey&#39;,legend=True) ax = trans.iloc[j,:].plot(label=f&#39;Scaled {j}&#39;,legend=True) train_X.mean().plot(label=&#39;Raw Mean&#39;, color=&#39;Black&#39;, legend = True) ax.legend(bbox_to_anchor=(1, 1)) plot_sample(n_samples=5) . SNV . The first preprocessing method we look at is standard normal variate (SNV). SNV standaridises each spectra (row), which may allowing models to focus on relative values within each spectra spectra rather than differences in absolute values between spectra. This is simple to implement, we just transpose the column based scaling method. As compared to the raw spectra, SNV increases the amplitude at each end while slightly decreasing ampliutes for the middle portion. . When we test SNV with a linear regression, we find that performance is poor. However, only a very small amount of regularisation is needed. . from sklearn.preprocessing import scale from sklearn.base import TransformerMixin, BaseEstimator class SNV(TransformerMixin, BaseEstimator): def fit(self, X, y=None, sample_weight=None): return self def transform(self, X, copy=None): return scale(X,axis=1) . plot_sample(SNV()) . from sklearn.linear_model import Ridge pls= Pipeline([(&#39;scaler&#39;, SNV()), (&#39;model&#39;, Ridge()) ]) space = [Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;)] opt = Optimiser(space,pls,train_X,train_y,splitter=splitter,groups=groups) model_snv,result_snv = opt.optimise(save_file=model_path+&#39;4_snv&#39;) . Best model had an MSE of 1.1665 Setting parameters as: {&#39;model__alpha&#39;: 0.001} Elapsed time: 34.7947 seconds . MSC . A similar method is multiplicative scatter correction (MSC). Wake the mean spectra ($X_m$)and for each spectra instance ($X_i$) calculate a linear regression $X_i=aX_m+b$. We then inverse this relationship st. we return $ frac{X_i-b}{a}$. Similar to SNV, this transforms data into a measure of deviation from the mean spectra. The great thing about these methods is that they are both parameterless. . We test MSC below. It is much slower than SNV (comparable to PLS) while giving an even worse performance. While the spectra we examined appear similar to SNV, when we examining the regression plot, several instances display high errors, which may be the reason for the poor performance. . class MSC(TransformerMixin, BaseEstimator): sample_means = None def fit(self, X, y=None, sample_weight=None): self.sample_means = np.mean(X,axis=0) return self def transform(self, X, copy=None): X_msc = np.zeros_like(X.values) for i in range(X.shape[0]): fit = np.polyfit(self.sample_means, X.values[i,:], 1, full=True) X_msc[i,:] = (X.values[i,:] - fit[0][1]) / fit[0][0] return X_msc . plot_sample(MSC()) . from sklearn.linear_model import Ridge pls= Pipeline([(&#39;scaler&#39;, MSC()), (&#39;model&#39;, Ridge()) ]) space = [Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;)] opt = Optimiser(space,pls,train_X,train_y,splitter=splitter,groups=groups) model_msc,result_msc = opt.optimise(save_file=model_path+&#39;4_msc&#39;) . Best model had an MSE of 2.0044 Setting parameters as: {&#39;model__alpha&#39;: 0.001} Elapsed time: 288.1634 seconds . Savitsky-Golay . The third class of preprocessing we look at is Savitsky-Golay interpolation, which replaces each point with a polynomial fitted to nearby points. This is particularly useful because derivatives of this polynomial can be taken. An implementation is given in the scipy.signal package. We wrap this in a sklearn class to be consistent with the other methods. Parameters here are the window length, the order of the polynomial and the order of the derivative. . from scipy.signal import savgol_filter class SavGol(TransformerMixin, BaseEstimator): def __init__(self, window_length=10, polyorder=2, deriv=0,mode=&#39;interp&#39;): self.window_length=window_length self.polyorder = polyorder self.deriv = deriv self.mode=mode def fit(self, X, y=None, sample_weight=None): return self def transform(self, X, copy=None): return savgol_filter(X,self.window_length, self.polyorder,deriv=self.deriv,mode=self.mode) . SavGol gives spectra very similar to the base spectra. Taking derivatives flattens the spectra and provides emphasis on the edge regions. . plot_sample(SavGol(window_length=17,polyorder=2,deriv=0)) . plot_sample(SavGol(window_length=13,polyorder=2,deriv=1)) . plot_sample(SavGol(window_length=13,polyorder=2,deriv=2)) . To test Savitsky-Golay, we search the order of derivative from {0,1,2} and the kernel width from {3,5,...,21}. The the optimal model taking no derivative. Unsuprisingly, the result (an MSE of 0.8264) is very similar to the base spectra. . from sklearn.linear_model import Ridge from skopt.space import Categorical pls= Pipeline([(&#39;scaler&#39;, SavGol(window_length=13,polyorder=2)), (&#39;model&#39;, Ridge()) ]) space = [Integer(3,21,name=&#39;scaler__window_length&#39;), Integer(0,2,name=&#39;scaler__deriv&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;)] opt = Optimiser(space,pls,train_X,train_y,splitter=splitter,groups=groups) model_savgol,result_savgol = opt.optimise(save_file=model_path+&#39;4_savgot&#39;) . Best model had an MSE of 0.8713 Setting parameters as: {&#39;scaler__window_length&#39;: 3, &#39;scaler__deriv&#39;: 0, &#39;model__alpha&#39;: 0.001} Elapsed time: 42.8308 seconds . Preprocessing Search . So far we&#39;ve introduced our preprocessing techniques (SNV, MSC, Sav-Gol) and found they are pretty dismal for a linear regression. However we need to add the caveat that linear regression does fairly well on this dataset, a moderate amount of regularisation gives results similar to PLS; the preprocessing methods may give better results for other learners. . To investigate this we plug each preprocessing scheme into a PLS-LWR model. We investigate the following schemes. Suffixed numbers indicate the order of the derivative for Savitsky Golay. . SNV | MSC | SavGol-1 | SavGol-2 | SNV - SavGol-1 | SNV - SavGol-2 | . from lwr import LocalWeightedRegression from skopt.space import Categorical pipe = Pipeline([(&#39;preprocess&#39;,StandardScaler()), (&#39;scaler&#39;,PLSRegression()), (&#39;model&#39;,LocalWeightedRegression()) ]) preprocess_options= [SNV(), MSC(), SavGol(window_length=13,polyorder=2,deriv=1), SavGol(window_length=13,polyorder=2,deriv=2), ] space = [Categorical(preprocess_options,name=&#39;preprocess&#39;), Integer(1,ncol,name=&#39;scaler__n_components&#39;), Integer(1,nrow,name=&#39;model__n_neighbours&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;) ] opt = Optimiser(space,pipe,train_X,train_y,splitter=splitter,groups=groups) model_1,result_1 = opt.optimise(save_file=model_path+&#39;4_pp-pls-lwr1&#39;) . pipe = Pipeline([(&#39;preprocess&#39;,SavGol(window_length=13,polyorder=2,deriv=1)), (&#39;scaler&#39;,PLSRegression()), (&#39;model&#39;,LocalWeightedRegression()) ]) space = [Integer(3,21,name=&#39;preprocess__window_length&#39;), Integer(0,2,name=&#39;preprocess__deriv&#39;), Integer(1,ncol,name=&#39;scaler__n_components&#39;), Integer(1,nrow,name=&#39;model__n_neighbours&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;) ] opt = Optimiser(space,pipe,train_X,train_y,splitter=splitter,groups=groups) model_2,result_2 = opt.optimise(save_file=model_path+&#39;4_pp-pls-lwr2&#39;) . Summary . In this notebook, we have investigated various spectral preprocessing schemes (SNV, MSC, and Savitsky Golay derivatives). We started out by showing how transformed spectra and building linear models on transformed data. These gave disappointing results on the mangoes dataset. Using these techniques as an additional preprocessing step for our PLS-LWR model gave more promising results. After first searching across all preprocessing types, the first derivative Savitisky-Golay method gave the most promising results. We refocused our search around this method, finding a set of parameters that set a new best cross-validation MSE of 0.7223. We evaluate this model on the test set below, with an MSE of xyz. . model_2,mse_test = evaluate(model_2,train_X,train_y,test_X,test_y,plot=True) .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/13/Preprocessing.html",
            "relUrl": "/mangoes/2022/06/13/Preprocessing.html",
            "date": " • Jun 13, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Domain Related Regessions",
            "content": "In this previous part, we introduced the Mangoes data set, performed explanatory analysis for the metadata, defined our evaluation approach and built a linear model. In this part, we extend the linear model by using Partial Least Squares (PLS) preprocessing and local sample weightings. . import pathlib import pandas as pd import numpy as np from matplotlib import pyplot as plt from tqdm.notebook import tqdm import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; from codetiming import Timer from sklearn.model_selection import GroupKFold from scikit_models import * from skopt.space import Real, Integer from lwr import LocalWeightedRegression from sklearn.pipeline import Pipeline import warnings warnings.filterwarnings(&#39;ignore&#39;) . . mangoes=load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) nrow,ncol=train_X.shape groups = train_cat[&#39;Pop&#39;] splitter=GroupKFold() . . Partial Least Squares . PLS is like a supervised equivalent to principal components (PCA) and is widely used for IR-spectra analysis. Like PCA, a change of basis is performed with features transformed along orthogonal axes. The difference between the two is that while PCA selects components that explain variance within X, PLS selects components from X that explain variance within y, making features extracted by PLS more suitable for regression. . We make a small change to the sklearn PLS implementation as it doesn&#39;t play nice with the Pipeline class; being a supervised learner, PLS transforms and returns both X and y in a tuple. Future steps in the pipeline expect only the transformed X values. . from sklearn.cross_decomposition import PLSRegression as PLS_ class PLSRegression(PLS_): def transform(self,X,y=None,copy=True): X = super().transform(X,copy=copy) return X . The optimial model takes 30 components, with a moderate amount of $l_2$ regularisation. Search took around 5 minutes (this varies by run), an order of magnitude more than the search run last post. In future approaches we may want to run PLS only once with 30 components so that for PLS we fit and transform the data only once. . from sklearn.linear_model import Ridge pls= Pipeline([(&#39;scaler&#39;, PLSRegression(n_components=10)), (&#39;model&#39;, Ridge()) ]) space = [Integer(2,ncol,name=&#39;scaler__n_components&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;) ] opt = Optimiser(space,pls,train_X,train_y,splitter=splitter,groups=groups) model_pls,result_pls = opt.optimise(save_file=model_path+&#39;3_pls&#39;) . Best model had an MSE of 0.8116 Setting parameters as: {&#39;scaler__n_components&#39;: 35, &#39;model__alpha&#39;: 0.27337815806191307} Elapsed time: 275.3796 seconds . Locally Weighted Regression . Another method to improve a linear regression is to use lazily calculated local instance weights. Rather than training a single, global, model, we define a model that takes unique weights for each prediction instance. This can be done in any number of ways. The approach we take is to use Euclidean distance between and assign the k closest training instances a weight of 1 and the rest weight of 0. An intuitive way to understand this is as a kNN model with voting done by linear regression. At train time, we store the training set. At test time, we calculate our closest k-neighbours on which a linear regression is trained. . The advantage of this local weighting approach is that we can avoid outliers in the training data, which may skew a linear model. This approach also better fits non-linear data, as we can create a globally non-linear model from locally linear parts. The downsides of this approach are that we increase the cost of making predictions, the model is less interpretable, and we can run into neighbourhood effects when data is less dense. . We run a search with the number of neighbours k ranging from 1 to $ frac{4}{5}nrow$, the size of each training set in cross-validation. Note that this is incredibly inefficient for large values of k. We find that an LWR is useless in this application. . from sklearn.preprocessing import StandardScaler lwr= Pipeline([(&#39;scaler&#39;,StandardScaler()), (&#39;model&#39;,LocalWeightedRegression()) ]) space = [Integer(0,1,name=&#39;scaler__with_mean&#39;), Integer(0,1,name=&#39;scaler__with_std&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;), Integer(1, nrow*4/5, name=&#39;model__n_neighbours&#39;) ] opt = Optimiser(space,lwr,train_X,train_y,splitter=splitter,groups=groups) model_lwr,result_lwr= opt.optimise(save_file=model_path+&#39;3_lwr&#39;) . Best model had an MSE of 0.7868 Setting parameters as: {&#39;scaler__with_mean&#39;: 0, &#39;scaler__with_std&#39;: 1, &#39;model__alpha&#39;: 0.0024967728668762105, &#39;model__n_neighbours&#39;: 4668} Elapsed time: 17004.9833 seconds . PLS and LWR . We now combine PLS and LWR models, giving an MSE score of 0.7590. Interestingly our model uses more components (71 rather than 31) than in the previous example. . plslwr = Pipeline([(&#39;scaler&#39;,PLSRegression()), (&#39;model&#39;,LocalWeightedRegression()) ]) space = [Integer(1,ncol,name=&#39;scaler__n_components&#39;), Integer(1,nrow*4/5,name=&#39;model__n_neighbours&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;) ] opt = Optimiser(space,plslwr,train_X,train_y,splitter=splitter,groups=groups) model_plslwr,result_plslwr = opt.optimise(save_file=model_path+&#39;3_plslwr&#39;) . Summary . In the previous notebook, we fitted a linear regression with a level of $l_2$ regularisation determined by search. This resulted in a model giving an MSE of 1.1290 on the test set. This notebook has built upon this model by using PLS feature extraction and lazy sample weights, a type of approach that is popular for NIR-spectroscopy problems. Neither technique gave good performance alone, but combined we set a new benchmark for cross-validation performance. On the test set, this approach scored an MSE of 0.8117, an improvement of -0.3173 over the previous notebook. . plslwr, mse_test = evaluate(plslwr,train_X,train_y,test_X,test_y,plot=True) .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/07/PLS.html",
            "relUrl": "/mangoes/2022/06/07/PLS.html",
            "date": " • Jun 7, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Evaluation",
            "content": "In the previous notebook, we introduced the Mangoes data set, performed explanatory analysis for the metadata, and built a linear model. In this notebook, we define our evaluation approach for future experiments. We want to avoid continuously evaluating the test set as then we may be selecting models that fit this set well due to chance alone. On the other hand, we need to validate the performance of our models at least occasionally. The middle-ground approach we will take is to select a single model from each notebook to be evaluated on the test set, with this selected by cross-validation on the training data. . The other element of our evaluation approach is search, we need a method to select hyperparameters. As a starting point, we use 50 evaluations for each search. As our models get more complex we may increase this budget, or switch to budgeting based on time. . import sys sys.path.append(&#39;/notebooks/Mangoes/src/&#39;) model_path = &#39;../models/&#39; import pathlib import pandas as pd import numpy as np from matplotlib import pyplot as plt from sklearn.model_selection import GroupKFold from scikit_models import * from skopt.space import Real, Integer from lwr import LocalWeightedRegression from sklearn.pipeline import Pipeline import warnings warnings.filterwarnings(&#39;ignore&#39;) . . mangoes=load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) nrow,ncol=train_X.shape . . Cross-Validation . A common cross-validation method for IR-spectra analysis is leave-one-out (in this case fruit), with leave-out-one-population used in applications on Mangoes. However there are concerns that this leads to overfitting, as its likely than for any one particular fruit/pop there is another very similar fruit/pop (As an aside we could measure this by using $kNN_{k=1}$ models, then measuring the deviation between leave-one-out cross-validation scores and train-test scores). Rather we go with the standard 5-fold cross-validation which is a good middle gorund of asking if we can repeat a good level of performance 5 times with decent sized test/validate populations. . The sklearn cross-validate functions (cross_validate, cross_val_score), take averages of scores. This is very practical, as it allows them to iterate over an evaluation function with little overhead, however returning functions of scores is not ideal. A better method is to combine the test predictions of each fold into a single set and score based on these. For mean squared error (MSE) this doesn&#39;t make a difference, but for an $R^2$ score, performance may be completely different. It also allows us to plot our results. A requirement for this to work is that each instance in a training set is used for testing only once (s.t. there is one unique prediction for each instance). Below we define our cross-validation function and an accompanying function to evaluate a model on the test data. . from sklearn.metrics import r2_score, mean_squared_error from sklearn.model_selection import GroupKFold, KFold def cross_validate(model,X,y,splitter=GroupKFold(),groups=None,plot=False,save_loc=None): preds = None ys = None for fold, (inds1,inds2) in enumerate(splitter.split(X,y,groups)): model.fit(X.iloc[inds1,:],y.iloc[inds1,:]) pred = model.predict(X.iloc[inds2,:]) if preds is None: preds = pred ys = y.iloc[inds2,:] else: preds = np.concatenate((preds,pred),axis=0) ys = np.concatenate((ys,y.iloc[inds2,:]),axis=0) r2 = r2_score(ys,preds) mse = mean_squared_error(ys,preds) if plot: ys = ys.flatten() preds = preds.flatten() m, b = np.polyfit(ys, preds, 1) fig, ax = plt.subplots() ls = np.linspace(min(ys),max(ys)) ax.plot(ls,ls*m+b,color = &quot;black&quot;, label = r&quot;$ hat{y}$ = &quot;+f&quot;{m:.4f}y + {b:.4f}&quot;) ax.scatter(x=ys,y=preds,label = r&quot;$R^2$&quot; + f&quot;={r2:.4f}&quot;) ax.set_xlabel(&#39;True Values&#39;) ax.set_ylabel(&#39;Predicted Values&#39;) ax.legend(bbox_to_anchor=(0.5,1)) if not save_loc is None: fig.savefig(save_loc) return mse def evaluate(model,train_X,train_y,test_X,test_y,plot=False,save_loc=None,log=True): test_y=test_y.values.flatten() model.fit(train_X,train_y) preds = model.predict(test_X) r2 = r2_score(test_y,preds) mse = mean_squared_error(test_y,preds) if log: print(f&quot;Test set MSE: {mse:.4f}&quot;) if plot: preds=preds.flatten() m, b = np.polyfit(test_y, preds, 1) fig, ax = plt.subplots() ls = np.linspace(min(test_y),max(test_y)) ax.plot(ls,ls*m+b,color = &quot;black&quot;, label = r&quot;$ hat{y}$ = &quot;+f&quot;{m:.4f}y + {b:.4f}&quot;) ax.scatter(x=test_y,y=preds,label = r&quot;$R^2$&quot; + f&quot;={r2:.4f}&quot;) ax.set_xlabel(&#39;True Values&#39;) ax.set_ylabel(&#39;Predicted Values&#39;) ax.legend(bbox_to_anchor=(0.5,1)) if not save_loc is None: fig.savefig(save_loc) return model, mse . Grouping instance . We use grouped KFold, with grouping done by Pop. As an exercise, we show the effect of grouping by comparing groups by FruitID and no grouping. Mixing populations between folds (grouping by fruit or no grouping) significantly improves validation performance. As the test set includes different populations, this won&#39;t affect the results of the final model, however, it may affect our decision of model to select. From here onwards we use grouping by Pop. . Our specific problem is to build a model based on the given populations that can extrapolate to unseen populations, so validating with groups based on Pop will give a better indication of the true performance than other methods. . from sklearn.linear_model import LinearRegression model = LinearRegression() #group by pop groups = train_data[&#39;Pop&#39;] splitter = GroupKFold(n_splits=5) print(f&#39;Grouped by Pop, MSE = {cross_validate(model,train_X,train_y,splitter=splitter,groups=groups)}&#39;) #group by Fruit_ID groups = train_data[&#39;Fruit_ID&#39;] splitter = GroupKFold(n_splits=5) print(f&#39;Grouped by Fruit, MSE = {cross_validate(model,train_X,train_y,splitter=splitter,groups=groups)}&#39;) #group by splitter= KFold(shuffle=True) print(f&#39;No Grouping, MSE = {cross_validate(model,train_X,train_y,splitter=splitter,groups=groups)}&#39;) . Grouped by Pop, MSE = 0.8236810194689146 Grouped by Fruit, MSE = 0.6800524561711946 No Grouping, MSE = 0.6723791264681583 . Search . Our task for search is to define a search procedure. Since we&#39;ve defined a custom cross-validation method, the sklearn grid_search_cv and random_search cv won&#39;t work. Luckily the scikit-optimize (skopt) package provides a more powerful interface for Bayesian optimisation that we can take advantage of. . We create an interface for the skopt package, by first defining an objective function, which takes a search space and returns a score based on cross-validation results. Any extra parameters for cross-validation are defined in initialisation. We then define an optimise function, which wraps our search with nice things like tqdm progress bars and optional outputs This function returns a copy of the model with parameters set to find a solution and a dictionary of the search results. All the heavy lifting here is done by the gp_minimize function, which runs Bayesian optimisation based around a Gaussian process regression kernel. In the future, we could extend this to use different kernels. . To create our grid-search and random-search methods, we cheat a little and use the initialisation methods from skopt. Random is just that, while grid search will divide the parameter space evenly to match the number of calls. This approach allows us to run Bayesian, random, and grid search using the same definitions of inputs and receiving the same outputs. . from tqdm.notebook import tqdm from codetiming import Timer from skopt import gp_minimize,dump from skopt.space import Real, Integer from skopt.plots import plot_convergence from skopt.utils import use_named_args from skopt.callbacks import VerboseCallback class TqdmCallback(tqdm): def __call__(self, res): super().update() def __getstate__(self): return [] def __setstate__(self, state): pass class Optimiser(): def __init__(self,space,model,X,y,splitter=KFold(),groups=None): self.space=space self.model=model self.X=X self.y=y self.splitter=splitter self.groups=groups def objective(self,**params): self.model.set_params(**params) return cross_validate(self.model, self.X, self.y, splitter=self.splitter,groups=self.groups) def bayesian_optimise(self,n_calls=50,random_state=0): obj = use_named_args(self.space)(self.objective) return gp_minimize(obj,self.space,n_calls=n_calls,random_state=random_state,callback=TqdmCallback(total=n_calls)) def random_optimise(self,n_calls=50, random_state=0): obj = use_named_args(self.space)(self.objective) return gp_minimize(obj,self.space,n_calls=n_calls,n_initial_points=n_calls,initial_point_generator=&#39;random&#39;, random_state=random_state,callback=TqdmCallback(total=n_calls)) def grid_optimise(self,n_calls=50, random_state=0): obj = use_named_args(self.space)(self.objective) return gp_minimize(obj,self.space,n_calls=n_calls,n_initial_points=n_calls,initial_point_generator=&#39;grid&#39;, random_state=random_state,callback=TqdmCallback(total=n_calls)) @Timer() def optimise(self,strategy=&quot;bayesian&quot;,n_calls=50, random_state=0,plot=True,save_file=None,log=True): if strategy==&quot;bayesian&quot;: result = self.bayesian_optimise(n_calls=n_calls, random_state=random_state) elif strategy==&quot;grid&quot;: result = self.grid_optimise(n_calls=n_calls, random_state=random_state) elif strategy==&quot;random&quot;: result = self.random_optimise(n_calls=n_calls, random_state=random_state) #set parameters of model params = {dim.name:result[&#39;x&#39;][i] for i,dim in enumerate(self.space)} model = self.model.set_params(**params) #save model and search if not save_file is None: del result.specs[&#39;args&#39;][&#39;func&#39;] #spaghetti code to not throw an error as the objective function is unserialisable dump(result,save_file+&#39;_search.pkl&#39;) dump(model, save_file+&#39;_model.joblib&#39;) #plot if plot: plot_convergence(result) # log/print results and include a regression plot: if log: print(f&#39;Best model had an MSE of {result.fun:.4f}&#39;) print(f&#39;Setting parameters as: {params}&#39;) if save_file is None: cross_validate(model, self.X,self.y,splitter=self.splitter,groups=self.groups,plot=True,save_loc=None) else: cross_validate(model, self.X,self.y,splitter=self.splitter,groups=self.groups,plot=True,save_loc=save_file+&#39;_plot.png&#39;) return model,result . Search for L2 Regularisation . We run each search variant below for the problem of finding an appropriate level of $l_2$ regularisation to add to a linear regression alongside a standardisation scheme. . To run our search we first define a model, which should be an sklearn type regression model. We then define our search space, with each dimension defined using one of skopt&#39;s provided classes (Integer, Float, Categorical). For each dimension, we define the range of values. For categorical variables, this is an explicit, list, while for real values (floats and integers) we defined the start and end range. We can also define log$_{10}$ sampling for numerical values. . from sklearn.preprocessing import StandardScaler from sklearn.linear_model import Ridge pipe = Pipeline([(&#39;scaler&#39;,StandardScaler()), (&#39;model&#39;,Ridge()) ]) space = [ Integer(0,1,name=&#39;scaler__with_mean&#39;), Integer(0,1,name=&#39;scaler__with_std&#39;), Real(1e-3, 1e3, name=&#39;model__alpha&#39;,prior=&#39;log-uniform&#39;) ] groups = train_data[&#39;Pop&#39;] splitter=GroupKFold() opt = Optimiser(space,pipe,train_X,train_y,splitter=splitter,groups=groups) . We demonstrate results for each class of search below. After our optimiser class is declared we can run multiple searches with no overhead. If we are unhappy with the results we can increase the number of calls or attempt a different seed. . print(&#39;Running Grid Search&#39;) model_grid,result_grid= opt.optimise(strategy=&quot;grid&quot;,save_file=model_path+&#39;2_linear_grid&#39;) . Running Grid Search Best model had an MSE of 0.8157 Setting parameters as: {&#39;scaler__with_mean&#39;: 1, &#39;scaler__with_std&#39;: 1, &#39;model__alpha&#39;: 0.005623413251903491} Elapsed time: 18.7806 seconds . print(&#39;Running Random Search&#39;) model_rand,result_rand = opt.optimise(strategy=&quot;random&quot;,save_file=model_path+&#39;2_linear_random&#39;) . Running Random Search Best model had an MSE of 0.8180 Setting parameters as: {&#39;scaler__with_mean&#39;: 0, &#39;scaler__with_std&#39;: 1, &#39;model__alpha&#39;: 0.019920586766671106} Elapsed time: 11.4246 seconds . print(&#39;Running Bayesian Search&#39;) model_bayes,result_bayes= opt.optimise(strategy=&quot;bayesian&quot;,save_file=model_path+&#39;2_linear_bayes&#39;) . Running Bayesian Search Best model had an MSE of 0.8157 Setting parameters as: {&#39;scaler__with_mean&#39;: 1, &#39;scaler__with_std&#39;: 1, &#39;model__alpha&#39;: 0.006159146375736338} Elapsed time: 31.7134 seconds . Results across the search were indifferent to mean centring, but scaled variance and added a small amount of $l_2$ regularisation. Bayesian and random search converge much quicker than grid search, with Bayesian search returning the best result by a small margin. . Summary . This notebook has introduced our cross-validation and search schemes. We used these search schemes to find an optimal $l_2$ regularisation and standardisation scheme. The selected model gave a training MSE of 0.8156. On the test set (shown below) this model scores an MSE of 1.091, a slight improvement upon the 1.1290 (-0.0380) scored by the base linear regression from the last notebook. . model_bayes,mse_test = evaluate(model_bayes,train_X,train_y,test_X,test_y,plot=True,log=True) . Test set MSE: 1.1147 .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/03/Evaluation.html",
            "relUrl": "/mangoes/2022/06/03/Evaluation.html",
            "date": " • Jun 3, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Introduction",
            "content": "Deep learning for tabular data is experiencing a slight renaissance. Several methods have emerged that can compete with boosting methods (such as XGBoost) in favourable conditions. NIR-spectrometry is a branch of tabular data that typically has two properties, large dimensionality and multicollinearity, which in theory make it suited to deep networks. Multilayer perceptron networks have been used for decades, and recently CNN architectures have been proposed, however, linear regression models and domain related preprocessing are still the predominant technique. For a detailed review of the NIR spectra literature, I defer to Anderson and Walsh. . Applications in Industry use huge amounts of test instances, for instance, automated grading in horticulture packhouses. These analyses rely on prior lab analysis for labelling data. As this analysis is relatively expensive (especially for large amounts of data), most datasets are proprietary. Enter the Mangoes dataset (Anderson et al.), a large NIR-spectroscopy dataset for estimating the relationship between spectra and the dry matter, a measure of the maturity of mango fruit. . This is the first part of a series comparing a range of deep networks to classical approaches to the Mangoes data set. The advantage of the Mangoes dataset is that models (and performance metrics) are publicly available for both classical (Anderson et al.) and deep network (Mishra and Passos) approaches. We can start by (re-)producing similar work and once the results are in line we can veer off and try new things. The plan is to start with simple linear models and gradually add complexity. Likely we will do the same for deep networks. Currently, the following parts are sketched in, with the plan for deep networks being less clear: . 1) Introduction - Exploratory data analysis and a first linear model. 2) Evaluation - Setup our cross-validation and search methods. 3) Spectral Regressions - Cover regression techniques commonly used for spectral applications. 4) Spectral Preprocessing - Cover preprocessing techniques commonly used for spectral applications. 5) Black Box tabular - Compare results to ensembles like RandomForest and XGGoost. 6) Deep Networks ... . This notebook introduces the Mangoes data set and performs exploratory data analysis. These are done in a literate programming style with text, code and outputs alongside each other. We use the nbdevlibrary. Code blocks marked with #export are reused in future notebooks, allowing us to incrementally build a library of tools. Occasionally code segments are deemed too complex/large for a notebook and these will be available in the GitHub repository. . Setup . We begin with imports and library settings which we will use for all notebooks. . import pathlib import pandas as pd import numpy as np from matplotlib import pyplot as plt from sklearn.pipeline import Pipeline np.random.seed(123) import warnings warnings.filterwarnings(&#39;ignore&#39;) . . Next, we define methods to parse the Mangoes data set. We write a method to load the data (load_mangoes). Training and test splits are provided in the data (for reproducibility) and we write a method to separate these (train_test_split). We then write a method to separate the spectra data, the target, and other variables into separate dataframes, with the option to limit the spectra to within certain boundaries. More details about these partitions will be provided below. . def load_mangoes(): mangoes = pd.read_csv(&quot;../data/mangoes_raw.csv&quot;) unique_spectra = mangoes[&#39;DM&#39;].unique() fruit_id_dict = {u:i for i,u in enumerate(unique_spectra)} mangoes[&#39;Fruit_ID&#39;] = mangoes[&#39;DM&#39;].apply(lambda x: fruit_id_dict[x]) return mangoes def train_test_split(data): train_inds = np.logical_not(data[&#39;Set&#39;]==&#39;Val Ext&#39;) test_inds = data[&#39;Set&#39;]==&#39;Val Ext&#39; train_data = data[train_inds] test_data = data[test_inds] return train_data, test_data def X_y_cat(data,min_X=285,max_X=1200): cat_vars=[&#39;Set&#39;,&#39;Season&#39;,&#39;Region&#39;,&#39;Date&#39;,&#39;Type&#39;,&#39;Cultivar&#39;,&#39;Pop&#39;,&#39;Temp&#39;,&#39;Fruit_ID&#39;] y_vars = [&#39;DM&#39;] X_vars = [i for i in data.columns if (not i in y_vars) and (not i in cat_vars)] X_vars = [i for i in X_vars if (int(i)&gt;= min_X) and (int(i)&lt;= max_X)] return data[X_vars], data[y_vars], data[cat_vars] . Running these methods we see that the dataset has 11691 instances, 10243 of which are marked for training and 1448 for testing. . mangoes = load_mangoes() train_data,test_data = train_test_split(mangoes) train_X, train_y, train_cat= X_y_cat(train_data) test_X, test_y, test_cat = X_y_cat(test_data) nrow,ncol=train_X.shape print(f&#39;Data shape: {mangoes.shape}&#39;) print(f&#39;Train data shape: {train_data.shape}&#39;) print(f&#39;Test data shape: {test_data.shape}&#39;) . Data shape: (11691, 316) Train data shape: (10243, 316) Test data shape: (1448, 316) . Taking a step back, below we show a sample of the entire dataset. The first 8 columns are metadata and the 9th, DM, is the target variable. The remaining columns are the spectra, corresponding to readings over 3nm intervals from 285-1200nm. Multiple readings are made for each mango fruit. Each spectrum is included twice, corresponding to two spectra readings. Several fruits are read more than twice, for example, multiple readings are made at different temperatures. Above we assigned a &#39;Fruit_ID&#39; column based on unique values of DM. This isn&#39;t perfect, different fruit may have the same DM at the precision present in the dataset, or fruit may have different DM values but may be a useful proxy. . print(mangoes.head()) . Set Season Region Date Type Cultivar Pop Temp DM 0 Cal 1 NT 2/10/2015 Hard Green Caly 2 Mid 16.792506 1 Cal 1 NT 2/10/2015 Hard Green Caly 2 Mid 16.792506 2 Cal 1 NT 2/10/2015 Hard Green Caly 2 Mid 16.070979 3 Cal 1 NT 2/10/2015 Hard Green Caly 2 Mid 16.070979 4 Cal 1 NT 2/10/2015 Hard Green Caly 2 Mid 16.394013 285 ... 1176 1179 1182 1185 1188 1191 1194 1197 1200 Fruit_ID 0 0 ... 0 0 0 0 0 0 0 0 0 0 1 0 ... 0 0 0 0 0 0 0 0 0 0 2 0 ... 0 0 0 0 0 0 0 0 0 1 3 0 ... 0 0 0 0 0 0 0 0 0 1 4 0 ... 0 0 0 0 0 0 0 0 0 2 [5 rows x 316 columns] . We also show a selection of spectra from the training portion of the dataset. Missing values in the dataset are coded as 0. Values are missing at each end of the spectrum and are coded as 0. Several columns are completely 0, as indicated by the flat lines at each of the below figures. Other columns are partially 0, likely due to different instruments being used to measure different groups of samples. The range of data that includes no missing data is 513-1050nm. Incidentally, this is the range that cuts off much of the noise seen at each end. . ax=train_X.mean().plot(label=&#39;Mean&#39;,legend=True) for i in range(0,4): train_X.iloc[i,:].plot(label=i,legend=True) . We also show the distributuon of the target (DM) for the non-test partitions of the data. This is fairly symmetrical and no outliers are present. . train_y.plot.hist(bins=50,density=True) . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . Anderson et al. used the 684-990nm range for their analysis, so for the sake of comparison, we will also use this range of wavelengths. This range gives significantly smoother data. . train_X, train_y, train_cat = X_y_cat(train_data,min_X=684,max_X=990) test_X, test_y, test_cat = X_y_cat(test_data,min_X=684,max_X=990) print(f&#39;Number of selected spectra variables: {train_X.shape[1]}&#39;) ax=train_X.mean().plot(label=&#39;Mean&#39;,legend=True) for i in range(0,4): train_X.iloc[i,:].plot(label=i,legend=True) . Number of selected spectra variables: 103 . Expoloratory Data Analysis . We now dive into all the non-spectra data present in the dataset. We do this for the training data as we want to avoid learning about the test data set for now. We look at distributions of the target and the mean spectra for each categorical variable. . The Set variable deliminates data into training (cal), tuning (tuning) and test (val ext) sets. Previously we used this variable by combining the cal and tuning sets into a combined training data set. Each set has near identical mean spectra; indicating that these splits can be replaced by any random sampling method. DM distributions vary slightly. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Set&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Set&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Set&#39;].value_counts() . Cal 7413 Tuning 2830 Name: Set, dtype: int64 . Data is taken over 4 growing Seasons. The 4th season is used for the test set, with seasons 1-3 grouped and then divided into training and tuning sets. As was the case for Set, spectra readings across seasons are consistent, while DM values vary slightly. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Season&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Season&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Season&#39;].value_counts() . 3 4966 1 3914 2 1363 Name: Season, dtype: int64 . The two growing Regions, NT and QD also display similar spectra readings with slightly different DM distributions. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Region&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Region&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Region&#39;].value_counts() . NT 7439 QLD 2804 Name: Region, dtype: int64 . The Physiological stage, or Type, Hard Green or Ripened significantly influences spectra readings and ripened fruit has a much tighter DM distribution. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Type&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Type&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Type&#39;].value_counts() . Hard Green 9151 Ripen 1092 Name: Type, dtype: int64 . Each Cultivar displays slightly different mean spectra; cultivars display more variance at the low end and converge towards the high end. DM distributions vary highly. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Cultivar&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Cultivar&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Cultivar&#39;].value_counts() . Caly 2997 KP 2285 HG 1479 R2E2 1207 1243 400 4069 400 1201 398 LadyJ 398 LadyG 348 Keitt 331 Name: Cultivar, dtype: int64 . Mangoes are taken from 94 different Populations (orchards). This variable impacts spectra readings to a greater degree than cultivar. There is likely a significant overlap between the cultivar and population variables. . train_data.groupby(&#39;Pop&#39;)[train_X.columns].mean().transpose().plot(legend=False) train_data[&#39;Pop&#39;].value_counts() . 6 308 5 298 10 293 11 276 13 240 ... 43 40 42 39 44 38 40 20 27 10 Name: Pop, Length: 94, dtype: int64 . Readings at different Temperature show the same spectra reading. DM results are identical for each temperature, which is expected as they share the same lab-based label. . train_data[&#39;DM&#39;].hist(by=train_data[&#39;Temp&#39;],bins=30,sharey=True,sharex=True,density =True) train_data.groupby(&#39;Temp&#39;)[train_X.columns].mean().transpose().plot() train_data[&#39;Temp&#39;].value_counts() . No 5870 Low 1480 Mid 1476 High 1417 Name: Temp, dtype: int64 . Explaining Variance . Having examined each categorical variable in turn we now perform a simple variance analysis. We build a linear model relating DM to categorical variables. This is done for each combination of categorical variables (with temperature and date excluded) so that by using $R^2$ scores we can calculate the marginal contribution (to percent of variance explained) by each categorical variable. . Iterating through each combination of variables, we see that Pop explains 0.5474% of the variance. Including Cultivar adds an extra 0.002% for a total of 0.5476%. We conclude that the effect of Region, Type, and Season variables are solely due to aggregates of Pop, or conversely, that the Pop variable absorbs all of the information of these variables. . from sklearn.preprocessing import OneHotEncoder from sklearn.linear_model import LinearRegression from itertools import combinations for i in range(1,6): oh_vars=[&#39;Season&#39;,&#39;Region&#39;,&#39;Type&#39;,&#39;Cultivar&#39;,&#39;Pop&#39;] for selected in list(combinations(oh_vars,i)): selected = list(selected) enc = OneHotEncoder() enc.fit(train_data[selected]) oh_vars1 = enc.transform(train_data[selected]) lin = LinearRegression() lin.fit(oh_vars1,train_y) score = lin.score(oh_vars1,train_y) print(f&#39;R2 score is {score:.4f} for {selected}&#39;) . R2 score is 0.0121 for [&#39;Season&#39;] R2 score is 0.0016 for [&#39;Region&#39;] R2 score is 0.0079 for [&#39;Type&#39;] R2 score is 0.1151 for [&#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Pop&#39;] R2 score is 0.0131 for [&#39;Season&#39;, &#39;Region&#39;] R2 score is 0.0270 for [&#39;Season&#39;, &#39;Type&#39;] R2 score is 0.1299 for [&#39;Season&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Season&#39;, &#39;Pop&#39;] R2 score is 0.0175 for [&#39;Region&#39;, &#39;Type&#39;] R2 score is 0.1151 for [&#39;Region&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Region&#39;, &#39;Pop&#39;] R2 score is 0.1232 for [&#39;Type&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Type&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.0378 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Type&#39;] R2 score is 0.1323 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Pop&#39;] R2 score is 0.1552 for [&#39;Season&#39;, &#39;Type&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Season&#39;, &#39;Type&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Season&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.1260 for [&#39;Region&#39;, &#39;Type&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Region&#39;, &#39;Type&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Region&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Type&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.1553 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Type&#39;, &#39;Cultivar&#39;] R2 score is 0.5474 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Type&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Season&#39;, &#39;Type&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Region&#39;, &#39;Type&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] R2 score is 0.5476 for [&#39;Season&#39;, &#39;Region&#39;, &#39;Type&#39;, &#39;Cultivar&#39;, &#39;Pop&#39;] . Variables like Region or Cultivar may well affect dry matter, we just cannot measure this as their variance is absorbed by Pop. If we wanted to compare say Cultivar and Pop we would need a dataset containing multiple cultivars for each population. . mangoes.groupby(&#39;Pop&#39;).agg({cat_var : &#39;unique&#39; for cat_var in train_cat}) . Set Season Region Date Type Cultivar Pop Temp Fruit_ID . Pop . 1 [Tuning] | [1] | [NT] | [27/09/2015] | [Hard Green] | [Caly] | [1] | [High, Low] | [2863, 2864, 2865, 2866, 2867, 2868, 2869, 287... | . 2 [Cal] | [1] | [NT] | [2/10/2015] | [Hard Green] | [Caly] | [2] | [Mid] | [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,... | . 3 [Cal] | [1] | [NT] | [9/10/2015] | [Hard Green] | [Caly] | [3] | [High, Low, Mid] | [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 5... | . 4 [Cal] | [1] | [NT] | [22/10/2015] | [Hard Green] | [Caly] | [4] | [High, Low, Mid] | [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 9... | . 5 [Cal] | [1] | [NT] | [23/10/2015] | [Hard Green] | [KP] | [5] | [High, Low, Mid] | [120, 121, 122, 123, 124, 125, 126, 127, 128, ... | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 108 [Val Ext] | [4] | [QLD] | [13/12/2018] | [Hard Green] | [Caly] | [108] | [No] | [4466, 4467, 4468, 4469, 4470, 4471, 4472, 447... | . 109 [Val Ext] | [4] | [QLD] | [19/01/2019] | [Ripen] | [HG] | [109] | [No] | [4506, 4507, 4508, 4509, 4510, 4511, 4512, 451... | . 110 [Val Ext] | [4] | [QLD] | [22/01/2019] | [Ripen] | [Caly] | [110] | [No] | [4546, 4547, 4548, 4549, 4550, 4551, 4552, 455... | . 111 [Val Ext] | [4] | [QLD] | [25/01/2019] | [Ripen] | [Caly] | [111] | [No] | [4586, 4587, 4588, 4589, 4590, 4591, 4592, 459... | . 112 [Val Ext] | [4] | [QLD] | [25/01/2019] | [Ripen] | [HG] | [112] | [No] | [4626, 4627, 4628, 4629, 4630, 4631, 4632, 463... | . 112 rows × 9 columns . A Linear Model and Summary . This notebook has introduced the mangoes dataset and performed a simple exploratory analysis, finding that the Pop variable explains over half the variance in the dataset. This has implications for test set performance, with the training and test sets consisting of distinct sets of populations. . In the next few notebooks, we will get into the meat and potatoes of building regression models. To finish this notebook off we train a linear model on the training portion of the data, which gives an MSE score of 1.1290 on the test set. . from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error model = LinearRegression() model.fit(train_X,train_y) preds = model.predict(test_X) mse = mean_squared_error(test_y,preds) print(f&quot;Test set MSE is: {mse:.4f}&quot;) . Test set MSE is: 1.1290 .",
            "url": "https://huonfraser.github.io/Mangoes/mangoes/2022/06/01/Introduction.html",
            "relUrl": "/mangoes/2022/06/01/Introduction.html",
            "date": " • Jun 1, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://huonfraser.github.io/Mangoes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://huonfraser.github.io/Mangoes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}